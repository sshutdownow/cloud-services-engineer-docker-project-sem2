# Проектная работа дисциплины «Docker-контейнеризация и хранение данных»

## Описание
В этой проектной работе нужно настроить контейнеризацию существующего приложения с использованием Docker и Docker Compose, а также обеспечить безопасность образов и контейнеров.

Изначально в проекте две части:
* backend — бэкенд приложения (Go).
* frontend — фронтенд приложения (Vue.js).

В рамках проекта выполнены следующие задачи:
* Оптимизированы Dockerfile для:
  * бэкенд: применена мультиэтапнная сборка, go-приложение собрано статически, для его запуска используется [пустой контейнер](https://hub.docker.com/_/scratch/), для healtheck добавленно [простое приложение на go](backend/cmd/healthcheck), тоже слинкованно статически. Размер образа после развёртывания - 16.5MB.
  * фронтенд: применена мультиэтапнная сборка, в качестве основы использован легковесный образ node:lts-alpine и создан [.dockerignore](https://cli.vuejs.org/ru/guide/deployment.html#docker-nginx), а для запуска nginx:stable-alpine. Размер образа после развёртывания 53.6MB.
* Добавлен ещё один контейнер - `gateway`, он использует образ `haproxy:lts-alpine` (размер на диске 32.3MB), `gateway` выполняет функцию балансировщика нагрузки. Он [использует DNS-резолвер докера для обнаружения](https://www.haproxy.com/blog/haproxy-on-docker-swarm-load-balancing-and-dns-service-discovery) добавления/удаления backend-серверов. Т.е. если мы меняем число экземпляров контейнеров go-бэкенд и/или и vue-фронтенд, haproxy это тут же обнаруживает и начинает распределять нагрузку по всем рабочим контейнерам. Это позволяет быстро адаптировать проект под изменения нагрузки. Кпрме этого, `haproxy` использует встроенную проверку работоспособности HTTP-сервисов в остальных контейнерах и в случае сбоя или отказа, исключает его из алгоритма балансировки, а после восстановления - возвращает.
* Настроен Docker Compose для оркестрации контейнеров:
  * описаны все сервисы: `backend`, `frontend` и `gateway`.
  * healthchecks и политики перезапуска сервисов. 
  * `gateway` запускается только по готовности `backend`, `frontend`.
  * реализована горизонтальная масштабируемость с балансировкой нагрузки
* Реализованы меры безопасности:
  * `gateway` - это единственный контейнер, который доступен напрямую из внешней сети (Интернет) по 80/tcp-порту, с остальными контейнерами он коммуницирует в рамках отдельной внутренней сети: 80/tcp для фронтенда, 8081/tcp для бэкенда.
  * Внутри всех контейнеров нет процессов, запущенных от root.
  * Чувствительная информация исключена из образов. В репозитории создан файл [.env](.env) для запуска при "ручном" клонировании, в нем содержится переменная DOCKER_USER, используемая в [docker-compose.yml](docker-compose.yml). Её значение совпадает с именем github-репозитория, т.е. общедоступно и секретом не является.
  * В [workflow](.github/workflows/deploy.yaml) добавленно сканирование образов на уязвимости с помощью trivy.
  * Настроены ограничения ресурсов: CPU и RAM.
  * Основная ФС в контейнерах монтируется в режиме только для чтения, для сохранения данных настроены volumes.
  * Настроены минимальные linux capabilities необходимые для работы приложений.

Запуск приложения при "ручном" клонировании репозитория:
* [Устанавливаем](https://docs.docker.com/compose/install/) docker compose, если ещё не установлен.
* Клонируем репозиторий на свой сервер: ```git clone https://github.com/sshutdownow/cloud-services-engineer-docker-project-sem2.git```
* Для быстрого запуска на linux/amd64 ```cd cloud-services-engineer-docker-project-sem2 && docker-compose up -d```
* Если OS/ARCH не linux/amd64, собираем образы и запускаем: ```cd cloud-services-engineer-docker-project-sem2 && docker-compose up -d --build```
  
Для остановки:
```docker-compose down```
